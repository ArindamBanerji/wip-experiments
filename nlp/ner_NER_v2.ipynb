{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArindamBanerji/wip-experiments/blob/master/nlp/ner_NER_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qqbe8odKdqk8",
        "outputId": "b63007da-7048-4cbe-fd64-f90597410c95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0Wr_x-RodqlC",
        "outputId": "a14e8b2a-a9a0-4fbc-f40f-3d8e4e037ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tfds.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QpAUBmRQdqlF"
      },
      "outputs": [],
      "source": [
        "# for the time  being comment out this piece \n",
        "\n",
        "# import wget\n",
        "url_download_from = \"https://gmb.let.rug.nl/releases/gmb-2.2.0.zip\"\n",
        "\n",
        "# !wget https://gmb.let.rug.nl/releases/gmb-2.2.0.zip\n",
        "# wget.download('Url', 'C:\\\\PathToMyDownloadFolder\\\\NewFileName.extension')\n",
        "# wget.download(url_download_from, \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X5QB_HxRdqlN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuV4ymzYdqlP",
        "outputId": "0522945c-1f89-4966-c560-2ddea9ba7645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runnig inn Google Colab : True\n"
          ]
        }
      ],
      "source": [
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "FNAMES_SAVED = False\n",
        "\n",
        "print (\"Runnig inn Google Colab :\", IN_COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSrkyCdndqlR",
        "outputId": "597b6292-e1b7-4114-8253-6711578faf7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ],
      "source": [
        "if (IN_COLAB) :\n",
        "    ######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "    ## Please ignore if not training on GPU       ##\n",
        "    ## this is important for running CuDNN on GPU ##\n",
        "\n",
        "    tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "    # chck if GPU can be seen by TF\n",
        "    tf.config.list_physical_devices('GPU')\n",
        "    # only if you want to see how commands are executed, uncomment below\n",
        "    # tf.debugging.set_log_device_placement(True)\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "      # Restrict TensorFlow to only use the first GPU\n",
        "      try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "      except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "    ###############################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "slnNGV5IfZOR"
      },
      "outputs": [],
      "source": [
        "if (IN_COLAB) :\n",
        "    from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeW3DuHhdqlU",
        "outputId": "bdd4702a-c484-4a44-f801-db78471dafa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/NLP/NER_EXPTS\n",
            "/content/drive/My Drive/NLP/NER_EXPTS/\n"
          ]
        }
      ],
      "source": [
        "if (IN_COLAB) :\n",
        "    mount_base = \"/content/drive/My Drive\"\n",
        "    # Load the Drive helper and mount\n",
        "  # This will prompt for authorization.\n",
        "    drive.mount('/content/drive')\n",
        "    mount_path = \"/content/drive/My Drive/NLP/NER_EXPTS\"\n",
        "    ner_dirnm = mount_path + \"/\"\n",
        "else :\n",
        "    mount_base = \"C:\\\\Users\\\\Arindam Banerji\\\\CopyFolder\\\\IOT_thoughts\\\\python-projects\"\n",
        "    mount_path = mount_base + \"\\\\NLP\\\\NER_EXPTS\"\n",
        "    ner_dirnm = \"G:\\\\My Drive\\\\NLP\\\\NER_EXPTS\\\\\"\n",
        "\n",
        "print (mount_path)\n",
        "print (ner_dirnm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7vbVuT7dqlY",
        "outputId": "fc0b379d-4d1a-49da-a77d-b329b93d7e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NLP/NER_EXPTS  :  True\n"
          ]
        }
      ],
      "source": [
        "path_exists = os.path.exists(mount_path)\n",
        "ner_dir_exists = os.path.exists(ner_dirnm)\n",
        "\n",
        "if path_exists : \n",
        "  print (mount_path, \" : \" , path_exists )\n",
        "else:\n",
        "  print ( \"Load correct dir \", mount_path )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb09VTctdqli",
        "outputId": "ecd65f51-bd04-4cce-a266-7fe87c38d60f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Changed working directory: /content/drive/My Drive/NLP/NER_EXPTS\n"
          ]
        }
      ],
      "source": [
        "# Print the current working directory\n",
        "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(mount_path)\n",
        "\n",
        "# Print the current working directory\n",
        "print(\"Changed working directory: {0}\".format(os.getcwd()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgwWnkH7dqlk",
        "outputId": "e614e14d-1ecd-4b56-c01b-7914ccd26501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./gmb-2.2.0/data/\n"
          ]
        }
      ],
      "source": [
        "data_root = './gmb-2.2.0/data/' if IN_COLAB == True else '.\\\\gmb-2.2.0\\\\data\\\\' \n",
        "\n",
        "print ( data_root) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JO-EhuLpKHgK"
      },
      "outputs": [],
      "source": [
        "fnames_list_fnm = ner_dirnm + \"fnames_list.data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9cD3OsWJKHgL"
      },
      "outputs": [],
      "source": [
        "def save_list_to_file ( fnames_list_fnm, fnames_list) :\n",
        "        with open(fnames_list_fnm, 'wb') as filehandle:\n",
        "            # Store the data as a binary data stream\n",
        "            pickle.dump(fnames_list, filehandle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z95-N-EjKHgM"
      },
      "outputs": [],
      "source": [
        "def load_list_from_file ( fnames_list_fnm) :\n",
        "    fnames_loaded = []\n",
        "    if os.path.isfile(fnames_list_fnm) and os.access(fnames_list_fnm, os.R_OK) :\n",
        "        with open(fnames_list_fnm, 'rb') as filehandle:\n",
        "            # Read the data as a binary data stream\n",
        "            fnames_loaded = pickle.load(filehandle)\n",
        "    return fnames_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D7BOVfQ6dqlm"
      },
      "outputs": [],
      "source": [
        "# data_root = './gmb-2.2.0/data/'\n",
        "\n",
        "fnames = []\n",
        "\n",
        "if os.path.isfile(fnames_list_fnm) and os.access(fnames_list_fnm, os.R_OK) :\n",
        "    fnames = load_list_from_file (fnames_list_fnm)\n",
        "else :\n",
        "        for root, dirs, files in os.walk(data_root):\n",
        "            for filename in files:\n",
        "                if filename.endswith(\".tags\"):\n",
        "                    fnames.append(os.path.join(root, filename))\n",
        "        \n",
        "        save_list_to_file (fnames_list_fnm, fnames)\n",
        "        FNAMES_SAVED = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jEsmqmTzKHgO",
        "outputId": "235881b2-f3ae-46c6-886f-6c89441538e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FNAMES were loaded from  /content/drive/My Drive/NLP/NER_EXPTS/fnames_list.data\n"
          ]
        }
      ],
      "source": [
        "if FNAMES_SAVED :\n",
        "    fnames_reloaded = load_list_from_file (fnames_list_fnm)\n",
        "    print (\"Are fnames && fnames_reloaded equal : \", (fnames == fnames_reloaded) )\n",
        "    print (\"FNAMES were saved to  \", fnames_list_fnm)\n",
        "else :\n",
        "    print (\"FNAMES were loaded from \", fnames_list_fnm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDotrlX5dqlq",
        "outputId": "9e83236e-b5f8-4240-9331-9363c974eb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num of files  10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.\\\\gmb-2.2.0\\\\data\\\\p00\\\\d0018\\\\en.tags',\n",
              " '.\\\\gmb-2.2.0\\\\data\\\\p00\\\\d0025\\\\en.tags']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "print (\" num of files \", len(fnames) )\n",
        "fnames[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HwFjOFwiKHgS"
      },
      "outputs": [],
      "source": [
        "# save_list_to_file (fnames_list_fnm, fnames)\n",
        "# fnames_loaded = load_list_from_file (fnames_list_fnm)\n",
        "# print (\"fnames is equal to fnames_loaded \", (fnames == fnames_loaded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "y7rL5m87KHgT",
        "outputId": "3d5d56b7-c8f4-4985-a4ef-a5f7824453c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory status  ./ner  :  True\n"
          ]
        }
      ],
      "source": [
        "ner_path = \"./ner\"\n",
        "\n",
        "ner_exists = os.path.exists(ner_path)\n",
        "num_files_in_ner = 0\n",
        "\n",
        "if ner_exists :\n",
        "    onlyfiles = next(os.walk(ner_path))[2]\n",
        "    num_files_in_ner = len(onlyfiles) \n",
        "    print ( len(onlyfiles) ) \n",
        "    shutil.rmtree(ner_path)\n",
        "               \n",
        "os.mkdir(ner_path)\n",
        "\n",
        "print (\"Directory status \", ner_path, \" : \", os.path.exists(ner_path) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1zAM8wMQdqlu"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import collections\n",
        " \n",
        "ner_tags = collections.Counter()\n",
        "iob_tags = collections.Counter()\n",
        "\n",
        "def strip_ner_subcat(tag):\n",
        "    # NER tags are of form {cat}-{subcat}\n",
        "    # eg tim-dow. We only want first part\n",
        "    return tag.split(\"-\")[0]\n",
        "\n",
        "\n",
        "def iob_format(ners):\n",
        "    # converts IO tags into BIO format\n",
        "    # input is a sequence of IO NER tokens\n",
        "    # convert this: O, PERSON, PERSON, O, O, LOCATION, O\n",
        "    # into: O, B-PERSON, I-PERSON, O, O, B-LOCATION, O\n",
        "    iob_tokens = []\n",
        "    for idx, token in enumerate(ners):\n",
        "        if token != 'O':  # !other\n",
        "            if idx == 0:\n",
        "                token = \"B-\" + token #start of sentence\n",
        "            elif ners[idx-1] == token:\n",
        "                token = \"I-\" + token  # continues\n",
        "            else:\n",
        "                token = \"B-\" + token\n",
        "        iob_tokens.append(token)\n",
        "        iob_tags[token] += 1\n",
        "    return iob_tokens  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zGTe83Rudqlv",
        "outputId": "2dd365c0-94d3-452b-9c94-20ab97e991ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1938f0e577bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\gmb-2.2.0\\\\data\\\\p00\\\\d0018\\\\en.tags'"
          ]
        }
      ],
      "source": [
        "total_sentences = 0\n",
        "outfiles = []\n",
        "for idx, file in enumerate(fnames):\n",
        "    with open(file, 'rb') as content:\n",
        "        data = content.read().decode('utf-8').strip()\n",
        "        sentences = data.split(\"\\n\\n\")\n",
        "        print(idx, file, len(sentences))\n",
        "        total_sentences += len(sentences)\n",
        "        \n",
        "        with open(\"./ner/\"+str(idx)+\"-\"+os.path.basename(file), \n",
        "                  'w', encoding='utf-8') as outfile:\n",
        "            outfiles.append(\"./ner/\"+str(idx)+\"-\"+os.path.basename(file))\n",
        "            writer = csv.writer(outfile)\n",
        "            \n",
        "            for sentence in sentences: \n",
        "                toks = sentence.split('\\n')\n",
        "                words, pos, ner = [], [], []\n",
        "                \n",
        "                for tok in toks:\n",
        "                    t = tok.split(\"\\t\")\n",
        "                    words.append(t[0])\n",
        "                    pos.append(t[1])\n",
        "                    ner_tags[t[3]] += 1\n",
        "                    ner.append(strip_ner_subcat(t[3]))\n",
        "                writer.writerow([\" \".join(words), \n",
        "                                 \" \".join(iob_format(ner)), \n",
        "                                 \" \".join(pos)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tJaNXc5dqly"
      },
      "outputs": [],
      "source": [
        "print(\"total number of sentences: \", total_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LADs0Is7dqlz"
      },
      "outputs": [],
      "source": [
        "print(\" nertags : \", ner_tags, \"\\n\")\n",
        "print(\"iob tags \", iob_tags, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk9GHVxMdql0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels, values = zip(*iob_tags.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgzhNH67dql1"
      },
      "outputs": [],
      "source": [
        "indexes = np.arange(len(labels))\n",
        "\n",
        "\n",
        "plt.bar(indexes, values)\n",
        "plt.xticks(indexes, labels, rotation='vertical')\n",
        "plt.margins(0.01)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0plNTatdql2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# could use `outfiles` param as well\n",
        "files = glob.glob(\"./ner/*.tags\")\n",
        "\n",
        "data_pd = pd.concat([pd.read_csv(f, header=None, \n",
        "                                 names=[\"text\", \"label\", \"pos\"]) \n",
        "                for f in files], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WohSWtwRdql2"
      },
      "outputs": [],
      "source": [
        "data_pd.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc7hxmnOdql3"
      },
      "outputs": [],
      "source": [
        "### Keras tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "text_tok = Tokenizer(filters='[\\\\]^\\t\\n', lower=False,\n",
        "                     split=' ', oov_token='<OOV>')\n",
        "\n",
        "pos_tok = Tokenizer(filters='\\t\\n', lower=False,\n",
        "                    split=' ', oov_token='<OOV>')\n",
        "\n",
        "ner_tok = Tokenizer(filters='\\t\\n', lower=False,\n",
        "                    split=' ', oov_token='<OOV>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzhLTkKDdql6"
      },
      "outputs": [],
      "source": [
        "text_tok.fit_on_texts(data_pd['text'])\n",
        "pos_tok.fit_on_texts(data_pd['pos'])\n",
        "ner_tok.fit_on_texts(data_pd['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PobHoRWCdql8"
      },
      "outputs": [],
      "source": [
        "ner_config = ner_tok.get_config()\n",
        "text_config = text_tok.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUFdK0-0dql9"
      },
      "outputs": [],
      "source": [
        "print(ner_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_BMyKikdql-"
      },
      "outputs": [],
      "source": [
        "text_vocab = eval(text_config['index_word'])\n",
        "ner_vocab = eval(ner_config['index_word'])\n",
        "\n",
        "print(\"Unique words in vocab:\", len(text_vocab))\n",
        "print(\"Unique NER tags in vocab:\", len(ner_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2KOXxSZdql_"
      },
      "outputs": [],
      "source": [
        "x_tok = text_tok.texts_to_sequences(data_pd['text'])\n",
        "y_tok = ner_tok.texts_to_sequences(data_pd['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS3WN_ykdql_"
      },
      "outputs": [],
      "source": [
        "print(text_tok.sequences_to_texts([x_tok[1]]), data_pd['text'][1])\n",
        "print(ner_tok.sequences_to_texts([y_tok[1]]), data_pd['label'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vkALp1jdqmA"
      },
      "outputs": [],
      "source": [
        "print(text_tok.sequences_to_texts([x_tok[2]]), data_pd['text'][1])\n",
        "print(ner_tok.sequences_to_texts([y_tok[2]]), data_pd['label'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHBMKDhGdqmC"
      },
      "outputs": [],
      "source": [
        "# now, pad seqences to a maximum length\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "x_pad = sequence.pad_sequences(x_tok, padding='post',\n",
        "                              maxlen=max_len)\n",
        "y_pad = sequence.pad_sequences(y_tok, padding='post',\n",
        "                              maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rtk7M-UdqmD"
      },
      "outputs": [],
      "source": [
        "print(x_pad.shape, y_pad.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_5lpSasdqmE"
      },
      "outputs": [],
      "source": [
        "text_tok.sequences_to_texts([x_pad[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l1DdFEmdqmF"
      },
      "outputs": [],
      "source": [
        "ner_tok.sequences_to_texts([y_pad[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqUtFOJgdqmG"
      },
      "outputs": [],
      "source": [
        "num_classes = len(ner_vocab)+1\n",
        "\n",
        "Y = tf.keras.utils.to_categorical(y_pad, num_classes=num_classes)\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8_KAZPVdqmG"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary \n",
        "vocab_size = len(text_vocab) + 1 \n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 100\n",
        "\n",
        "#batch size\n",
        "BATCH_SIZE=90\n",
        "\n",
        "# num of NER classes\n",
        "num_classes = len(ner_vocab)+1\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
        "\n",
        "dropout=0.2\n",
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, classes):\n",
        "  model = tf.keras.Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    Bidirectional(LSTM(units=rnn_units,\n",
        "                           return_sequences=True,\n",
        "                           dropout=dropout,  \n",
        "                           kernel_initializer=tf.keras.initializers.he_normal())),\n",
        "    TimeDistributed(Dense(rnn_units, activation='relu')),\n",
        "    Dense(num_classes, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKo1UldhdqmI"
      },
      "outputs": [],
      "source": [
        "model = build_model_bilstm(\n",
        "                        vocab_size = vocab_size,\n",
        "                        embedding_dim=embedding_dim,\n",
        "                        rnn_units=rnn_units,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        classes=num_classes)\n",
        "model.summary()\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEkHHqkxdqmM"
      },
      "outputs": [],
      "source": [
        "X = x_pad "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjwuDHGGdqmO"
      },
      "outputs": [],
      "source": [
        "# create training and testing splits\n",
        "total_sentences = 62010\n",
        "test_size = round(total_sentences / BATCH_SIZE * 0.2)\n",
        "X_train = X[BATCH_SIZE*test_size:]\n",
        "Y_train = Y[BATCH_SIZE*test_size:]\n",
        "\n",
        "X_test = X[0:BATCH_SIZE*test_size]\n",
        "Y_test = Y[0:BATCH_SIZE*test_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC0G7U5-dqmO"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPo0irI_dqmP"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf3gk6SVKHgs"
      },
      "outputs": [],
      "source": [
        "# batch size in eval\n",
        "model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbzmPQxbKHgs"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8rAjd1tKHgt"
      },
      "outputs": [],
      "source": [
        "text_tok.sequences_to_texts([X_test[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6FC5nCqKHgt"
      },
      "outputs": [],
      "source": [
        "ner_tok.sequences_to_texts([y_pad[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zXvCTohKHgu"
      },
      "outputs": [],
      "source": [
        "y_pred = tf.argmax(y_pred, -1)\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIuu4v4hKHgv"
      },
      "outputs": [],
      "source": [
        "y_pnp = y_pred.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3QXJvwKHgv"
      },
      "outputs": [],
      "source": [
        "ner_tok.sequences_to_texts([y_pnp[4]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('kaggle_expts_venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "be4c78cf3439baca13423b01e59fbae7d194fbbd5ee65de83dc38866596fbf17"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}